{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting painting authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will build a model to predict authors of paintings. I will use the [dataset](https://www.kaggle.com/datasets/ikarus777/best-artworks-of-all-time) from Kaggle that has 8,000+ paintings by 50 most famous artists to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with importing the necessary libraries and exploring the information about the paintings in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8446 files belonging to 50 classes.\n",
      "Using 6757 files for training.\n",
      "Found 8446 files belonging to 50 classes.\n",
      "Using 1689 files for validation.\n"
     ]
    }
   ],
   "source": [
    "image_size = (256, 256)\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    'data\\images',\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=17,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "valid_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    'data\\images',\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=17,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "valid_ds = valid_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255),\n",
    "    tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(50)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "  train_ds,\n",
    "  validation_data=valid_ds,\n",
    "  epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.vgg16.VGG16(input_shape = (256, 256, 3), include_top = False, weights = 'imagenet')\n",
    "base_model.trainable = False\n",
    "\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = tf.keras.layers.Dense(50)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  global_average_layer,\n",
    "  prediction_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 556s 6us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.ResNet50(input_shape=(256, 256,3), include_top=False, weights=\"imagenet\")\n",
    "base_model.trainable = False\n",
    "\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = tf.keras.layers.Dense(50)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  global_average_layer,\n",
    "  prediction_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "212/212 [==============================] - 594s 3s/step - loss: 2.1536 - accuracy: 0.4398 - val_loss: 1.5746 - val_accuracy: 0.5678\n",
      "Epoch 2/10\n",
      "212/212 [==============================] - 565s 3s/step - loss: 1.0996 - accuracy: 0.6916 - val_loss: 1.3613 - val_accuracy: 0.6157\n",
      "Epoch 3/10\n",
      "212/212 [==============================] - 586s 3s/step - loss: 0.7720 - accuracy: 0.7913 - val_loss: 1.2508 - val_accuracy: 0.6501\n",
      "Epoch 4/10\n",
      "212/212 [==============================] - 605s 3s/step - loss: 0.5741 - accuracy: 0.8548 - val_loss: 1.1933 - val_accuracy: 0.6684\n",
      "Epoch 5/10\n",
      "212/212 [==============================] - 581s 3s/step - loss: 0.4401 - accuracy: 0.9023 - val_loss: 1.1759 - val_accuracy: 0.6838\n",
      "Epoch 6/10\n",
      "212/212 [==============================] - 580s 3s/step - loss: 0.3451 - accuracy: 0.9315 - val_loss: 1.1811 - val_accuracy: 0.6939\n",
      "Epoch 7/10\n",
      "212/212 [==============================] - 576s 3s/step - loss: 0.2755 - accuracy: 0.9523 - val_loss: 1.1899 - val_accuracy: 0.6868\n",
      "Epoch 8/10\n",
      "212/212 [==============================] - 542s 3s/step - loss: 0.2233 - accuracy: 0.9691 - val_loss: 1.1973 - val_accuracy: 0.6874\n",
      "Epoch 9/10\n",
      "212/212 [==============================] - 536s 3s/step - loss: 0.1833 - accuracy: 0.9784 - val_loss: 1.2039 - val_accuracy: 0.6903\n",
      "Epoch 10/10\n",
      "212/212 [==============================] - 525s 2s/step - loss: 0.1520 - accuracy: 0.9856 - val_loss: 1.2086 - val_accuracy: 0.6933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bbfb93fd00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "  train_ds,\n",
    "  validation_data=valid_ds,\n",
    "  epochs=10\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de4d66f7636782b71c6240bd3d76ca11d0503bfdc5159caa903020d75a201e7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
